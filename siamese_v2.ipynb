{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T11:30:28.275103",
     "start_time": "2017-10-25T11:30:28.157818"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Dense, Dropout, Input, Lambda\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import classification_report\n",
    "from itertools import product\n",
    "from sklearn.metrics import accuracy_score as accuracy\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import mode\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "input_dim = 784\n",
    "num_classses = 10\n",
    "img_rows, img_cols = 28, 28\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NNHandler():\n",
    "    \n",
    "    def load_data(path):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T09:53:49.947713",
     "start_time": "2017-10-25T09:53:49.414933"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_data(X, y):\n",
    "    #create tensor variant of 2D images\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        X = X.reshape(X.shape[0], 1, img_rows, img_cols)\n",
    "        input_shape = (1, img_rows, img_cols)\n",
    "    else:\n",
    "        X = X.reshape(X.shape[0], img_rows, img_cols, 1)\n",
    "        input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "    X = X.astype('float32') / 255\n",
    "    #X = (X - np.mean(X)) / np.std(X)\n",
    "    # convert class vectors to binary class matrices\n",
    "    #y = keras.utils.to_categorical(y, num_classes)\n",
    "    return X, y, input_shape\n",
    "\n",
    "data=np.load(\"FashionData/FashionPDEngDM.npz\")\n",
    "\n",
    "## Labeled training set for classes 1,2,3,8,9 (30000 samples)\n",
    "x_train_12389_labeled = data[\"x_train_12389_labeled\"]\n",
    "y_train_12389_labeled = data[\"y_train_12389_labeled\"]\n",
    "\n",
    "## Labeled training set for classes 0,4,5,6,7 (just 5 samples)\n",
    "x_train_04567_labeled=data[\"x_train_04567_labeled\"]\n",
    "y_train_04567_labeled=data[\"y_train_04567_labeled\"]\n",
    "\n",
    "## Unlabeled training set for classes 0,4,5,6,7 (29992 samples)>\n",
    "x_train_04567_unlabeled=data[\"x_train_04567_unlabeled\"]\n",
    "\n",
    "## Labeled test set for classes 1,2,3,8,9\n",
    "x_test_12389=data[\"x_test_12389\"]\n",
    "y_test_12389=data[\"y_test_12389\"]\n",
    "\n",
    "##Labeled test set for classes 0,4,5,6,7 (this is where we are interested to obtain the highest accuracy possible - project goal)\n",
    "x_test_04567=data[\"x_test_04567\"]\n",
    "y_test_04567=data[\"y_test_04567\"]\n",
    "\n",
    "x_train_12389_labeled, y_train_12389_labeled, input_shape = preprocess_data(x_train_12389_labeled, y_train_12389_labeled)\n",
    "x_test_12389, y_test_12389, _ = preprocess_data(x_test_12389, y_test_12389)\n",
    "\n",
    "x_train_04567_labeled, y_train_04567_labeled, input_shape = preprocess_data(x_train_04567_labeled, y_train_04567_labeled)\n",
    "x_test_04567, y_test_04567, _ = preprocess_data(x_test_04567, y_test_04567)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T10:37:59.058552",
     "start_time": "2017-10-25T10:37:59.051535"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# image augumentation\n",
    "rotation_range = 50\n",
    "width_shift_range = 0.5\n",
    "height_shift_range = 0.5\n",
    "shear_range = 0.5\n",
    "horizontal_flip = True\n",
    "vertical_flip = True\n",
    "fill_mode = 'nearest'\n",
    "zoom_range = 0.2\n",
    "x_train_04567_aug = ImageDataGenerator(\n",
    "    rotation_range = rotation_range,\n",
    "    shear_range = shear_range,\n",
    "    width_shift_range= width_shift_range,\n",
    "    height_shift_range= height_shift_range,\n",
    "    horizontal_flip = horizontal_flip,\n",
    "    vertical_flip = vertical_flip,\n",
    "    zoom_range = zoom_range,\n",
    "    fill_mode = fill_mode\n",
    ")\n",
    "x_train_04567_aug.fit(x_train_04567_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T11:31:04.215182",
     "start_time": "2017-10-25T11:31:01.637388"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# display and generate augmented data \n",
    "def get_augmented_data(generator, x, y, N, visualize = False):\n",
    "    \"\"\"Generate augmented data.\n",
    "    \n",
    "    Params: \n",
    "    - generator: ImageGenerator \n",
    "    - x: X data\n",
    "    - y: y data\n",
    "    - N: number of images to generates per class\n",
    "    - visualize: whether to visualize the augmented images\n",
    "    \n",
    "    Return: (x, y) augmneted data\n",
    "    \"\"\"\n",
    "    \n",
    "    x_train_04567_aug_generated = []\n",
    "    y_train_04567_aug_generated = []\n",
    "\n",
    "    data_len = len(x)    \n",
    "    data_gen = generator.flow(x, y, batch_size = data_len)\n",
    "    num_batch_print = 2\n",
    "    num_columns = 2\n",
    "\n",
    "    for i, data_batch in enumerate(data_gen):    \n",
    "        if N <= i: # in every iteration, one instance per class is generated\n",
    "            break\n",
    "       \n",
    "        x_batch, y_batch = data_batch\n",
    "        #save data\n",
    "        x_train_04567_aug_generated.append(x_batch)\n",
    "        y_train_04567_aug_generated.append(y_batch)\n",
    "        \n",
    "        if visualize: # visualize the augmented results\n",
    "            f, axarr = plt.subplots(data_len, num_columns, figsize = (5, 5))\n",
    "            for j in range(len(x_batch)):\n",
    "                ground_ind = np.where(y == y_batch[j])\n",
    "                axarr[j, 0].imshow(x[ground_ind].reshape((28,28)), cmap='gray')   \n",
    "                axarr[j, 1].imshow(x_batch[j].reshape((28,28)), cmap='gray')\n",
    "                axarr[j, 0].axis('off')\n",
    "                axarr[j, 1].axis('off')\n",
    "            print(i)\n",
    "            plt.show()\n",
    "    \n",
    "    x_train_04567_aug_generated[-1]\n",
    "    # reshaping such that the array has the shape of (# data, 28, 28, 1)\n",
    "    x_train_04567_aug_generated = np.array(x_train_04567_aug_generated).reshape((-1, 28, 28, 1)) \n",
    "  \n",
    "    #reshaping to shape of (# data)\n",
    "    y_train_04567_aug_generated = np.array(y_train_04567_aug_generated).reshape((-1)) \n",
    "#    modulo = N % data_len\n",
    "#     if modulo != 0:\n",
    "#         x_train_04567_aug_generated = x_train_04567_aug_generated[0 : -(data_len-modulo)]\n",
    "#         y_train_04567_aug_generated = y_train_04567_aug_generated[0 : -(data_len-modulo)]\n",
    "#         print(\"Readjusting the shape. The shape is %s \" % (x_train_04567_aug_generated.shape, ))\n",
    "        #print(\"Warning: The data lenght will be slightly bigger than N, because N is not divadable by size of data.\")\n",
    "    return x_train_04567_aug_generated, y_train_04567_aug_generated\n",
    "\n",
    "x_train_04567_aug_generated, y_train_04567_aug_generated = get_augmented_data(generator = x_train_04567_aug, \n",
    "                                                                              x = x_train_04567_labeled,\n",
    "                                                                              y = y_train_04567_labeled,\n",
    "                                                                              N = 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T11:31:05.022316",
     "start_time": "2017-10-25T11:31:04.216142"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training pairs is 20993 \n",
      "Number of val pairs is 8997 \n"
     ]
    }
   ],
   "source": [
    "# create training+test positive and negative pairs\n",
    "def create_pairs(x, class_indices, num_classes):\n",
    "    '''Positive and negative pair creation.\n",
    "    Alternates between positive and negative pairs. \n",
    "\n",
    "    Maximally creates (min(class_size) - 1) * num_classes pairs.\n",
    "    '''\n",
    "    pairs = []\n",
    "    labels = []    \n",
    "    n = min([len(class_indices[d]) for d in range(num_classes)]) - 1\n",
    "    for d in range(num_classes):\n",
    "        for i in range(n):\n",
    "            z1, z2 = class_indices[d][i], class_indices[d][i+1]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            inc = random.randrange(1, num_classes)\n",
    "            dn = (d + inc) % num_classes # this guarantees that the same class will not be selected\n",
    "            z1, z2 = class_indices[d][i], class_indices[dn][i]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            labels += [1, 0]\n",
    "    return np.array(pairs), np.array(labels)\n",
    "\n",
    "ind_04567 = [0,4,5,6,7]\n",
    "class_indices = [np.where(y_train_04567_aug_generated == i)[0] for i in ind_04567]\n",
    "x_pairs, y_pairs = create_pairs(x_train_04567_aug_generated, class_indices, int(num_classes / 2))\n",
    "x_train_pairs, x_val_pairs, y_train_pairs, y_val_pairs = train_test_split(x_pairs, y_pairs, test_size=0.3, random_state=42)\n",
    "print(\"Number of training pairs is %d \" % x_train_pairs.shape[0])\n",
    "print(\"Number of val pairs is %d \" % x_val_pairs.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T18:00:19.310414",
     "start_time": "2017-10-25T18:00:18.954484"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\azika\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:44: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"la..., inputs=[<tf.Tenso...)`\n"
     ]
    }
   ],
   "source": [
    "# model definition\n",
    "def create_base_network(input_shape):\n",
    "    '''Base network to be shared (eq. to feature extraction).\n",
    "    '''\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))    \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))    \n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    return model\n",
    "\n",
    "def get_abs_diff(vects):\n",
    "    x, y = vects\n",
    "    return K.abs(x - y)  \n",
    "\n",
    "def get_l2_norm(vects):\n",
    "    x, y = vects\n",
    "    return K.sqrt(K.mean(K.square(x - y)))\n",
    "\n",
    "def abs_diff_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return shape1  \n",
    "\n",
    "base_network = create_base_network(input_shape)\n",
    "\n",
    "input_a = Input(shape = input_shape)\n",
    "input_b = Input(shape = input_shape)\n",
    "\n",
    "# because we re-use the same instance `base_network`,\n",
    "# the weights of the network will be shared across the two branches\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "abs_diff = Lambda(get_l2_norm, output_shape = abs_diff_output_shape)([processed_a, processed_b])\n",
    "\n",
    "#flattened_weighted_distance = Dense(1, activation = 'sigmoid')(abs_diff)\n",
    "\n",
    "siamese_model = Model(input=[input_a, input_b], output = abs_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T18:09:20.081829",
     "start_time": "2017-10-25T18:00:22.780533"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\azika\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:29: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "20993/20993 [==============================] - 106s - loss: 0.2571   \n",
      "Epoch 2/5\n",
      "20993/20993 [==============================] - 105s - loss: 0.2531   \n",
      "Epoch 3/5\n",
      "20993/20993 [==============================] - 108s - loss: 0.2512   \n",
      "Epoch 4/5\n",
      "20993/20993 [==============================] - 105s - loss: 0.2517   \n",
      "Epoch 5/5\n",
      "20993/20993 [==============================] - 109s - loss: 0.2514   \n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "def step_decay(epoch):\n",
    "    '''Learning rate step decay following the original paper.'''\n",
    "    initial_lrate = 0.001\n",
    "    drop = 0.99\n",
    "    epochs_drop = 1\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "def contrastive_loss(y, d):\n",
    "    \"\"\" Contrastive loss from Hadsell-et-al.'06\n",
    "        http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    \"\"\"\n",
    "    margin = 1\n",
    "    return K.mean((1 - y) * K.square(d) + y * K.square(K.maximum(margin - d, 0)))\n",
    "\n",
    "nb_epoch = 5\n",
    "optimizer = Adam()\n",
    "\n",
    "siamese_model.compile(loss = contrastive_loss, optimizer = optimizer)\n",
    "\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "callbacks_list = [lrate]\n",
    "\n",
    "siamese_model.fit([x_train_pairs[:, 0], x_train_pairs[:, 1]], #pairs \n",
    "          y_train_pairs, #labels of the pairs\n",
    "          callbacks = callbacks_list,\n",
    "          batch_size=128,\n",
    "          nb_epoch=nb_epoch)\n",
    "siamese_model.save('siamese_model_without_dense.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T18:09:36.027882",
     "start_time": "2017-10-25T18:09:20.643991"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# validation accuracy\n",
    "y_val_pred_proba = siamese_model.predict([x_val_pairs[:, 0], x_val_pairs[:, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T18:09:36.032893",
     "start_time": "2017-10-25T18:09:36.028882"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Accuracy of classifying the val set: 49.38%\n"
     ]
    }
   ],
   "source": [
    "# validation accuracy\n",
    "y_val_pred_class = y_val_pred_proba > 0.5 \n",
    "y_val_pred_class = y_val_pred_class.reshape(-1)\n",
    "val_accur = np.sum(y_val_pred_class == y_val_pairs) / len(y_val_pairs)\n",
    "print('* Accuracy of classifying the val set: {:.2%}'.format(val_accur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T18:09:36.047933",
     "start_time": "2017-10-25T18:09:36.033895"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# generate examples (k per class) that will be couples with test data\n",
    "k = 3 # k from from analogy of k-means\n",
    "x_test_04567_aug_generated, y_test_04567_aug_generated = get_augmented_data(generator = x_train_04567_aug, \n",
    "                                                                            x = x_train_04567_labeled,\n",
    "                                                                            y = y_train_04567_labeled,\n",
    "                                                                            N = k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T18:11:29.510518",
     "start_time": "2017-10-25T18:09:36.049939"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# create pairs\n",
    "x_test_pairs = np.array(list(product(x_test_04567, x_test_04567_aug_generated)))\n",
    "\n",
    "# predict the probability of a pair being similar. \n",
    "y_test_pred_prob = siamese_model.predict([x_test_pairs[:, 0], x_test_pairs[:, 1]])\n",
    "\n",
    "# reshaping such that each row contains k*number of class probabilities \n",
    "y_test_pred_prob = y_test_pred_prob.reshape(len(x_test_04567), len(x_test_04567_aug_generated))\n",
    "\n",
    "# getting top k prediction for a class\n",
    "y_test_pred_class_inds = y_test_pred_prob.argsort(axis = 1)[:, -k:]\n",
    "\n",
    "# like argsort but only for the highest score\n",
    "#y_test_pred_class_inds = np.argmax(y_test_pred_prob, axis = 1)\n",
    "\n",
    "# reverse order -> the highest prob is on the first place (This does not work! it reserve the data )\n",
    "#y_test_pred_class_inds = y_test_pred_class_inds[::-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T18:11:29.947751",
     "start_time": "2017-10-25T18:11:29.511519"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# generating class prediction\n",
    "y_test_pred_k = np.array([mode(y_test_04567_aug_generated[y_test_pred_class_inds[i]]) \n",
    "                                for i in range(len(y_test_pred_class_inds))])[:, 0]\n",
    "y_test_pred_k = y_test_pred_k.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T18:11:29.958710",
     "start_time": "2017-10-25T18:11:29.949715"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 4, 5]), array([4525,  230,  245], dtype=int64))"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many prediction per class\n",
    "np.unique(y_test_pred_k, return_counts= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T18:11:29.964736",
     "start_time": "2017-10-25T18:11:29.961723"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Accuracy of classifying the test set: 19.60%\n"
     ]
    }
   ],
   "source": [
    "# final accuracy\n",
    "test_accur = np.sum(y_test_pred_k == y_test_04567) / len(y_test_04567)\n",
    "print('* Accuracy of classifying the test set: {:.2%}'.format(test_accur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
