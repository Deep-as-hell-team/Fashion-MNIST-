{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T10:13:31.382656",
     "start_time": "2017-10-25T10:13:31.368617"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Dense, Dropout, Input, Lambda\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import classification_report\n",
    "from itertools import product\n",
    "from sklearn.metrics import accuracy_score as accuracy\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import mode\n",
    "import math\n",
    "\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "input_dim = 784\n",
    "num_classses = 10\n",
    "img_rows, img_cols = 28, 28\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T09:53:49.947713",
     "start_time": "2017-10-25T09:53:49.414933"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_data(X, y):\n",
    "    #create tensor variant of 2D images\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        X = X.reshape(X.shape[0], 1, img_rows, img_cols)\n",
    "        input_shape = (1, img_rows, img_cols)\n",
    "    else:\n",
    "        X = X.reshape(X.shape[0], img_rows, img_cols, 1)\n",
    "        input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "    X = X.astype('float32') / 255\n",
    "    #X = (X - np.mean(X)) / np.std(X)\n",
    "    # convert class vectors to binary class matrices\n",
    "    #y = keras.utils.to_categorical(y, num_classes)\n",
    "    return X, y, input_shape\n",
    "\n",
    "data=np.load(\"FashionData/FashionPDEngDM.npz\")\n",
    "\n",
    "## Labeled training set for classes 1,2,3,8,9 (30000 samples)\n",
    "x_train_12389_labeled = data[\"x_train_12389_labeled\"]\n",
    "y_train_12389_labeled = data[\"y_train_12389_labeled\"]\n",
    "\n",
    "## Labeled training set for classes 0,4,5,6,7 (just 5 samples)\n",
    "x_train_04567_labeled=data[\"x_train_04567_labeled\"]\n",
    "y_train_04567_labeled=data[\"y_train_04567_labeled\"]\n",
    "\n",
    "## Unlabeled training set for classes 0,4,5,6,7 (29992 samples)>\n",
    "x_train_04567_unlabeled=data[\"x_train_04567_unlabeled\"]\n",
    "\n",
    "## Labeled test set for classes 1,2,3,8,9\n",
    "x_test_12389=data[\"x_test_12389\"]\n",
    "y_test_12389=data[\"y_test_12389\"]\n",
    "\n",
    "##Labeled test set for classes 0,4,5,6,7 (this is where we are interested to obtain the highest accuracy possible - project goal)\n",
    "x_test_04567=data[\"x_test_04567\"]\n",
    "y_test_04567=data[\"y_test_04567\"]\n",
    "\n",
    "x_train_12389_labeled, y_train_12389_labeled, input_shape = preprocess_data(x_train_12389_labeled, y_train_12389_labeled)\n",
    "x_test_12389, y_test_12389, _ = preprocess_data(x_test_12389, y_test_12389)\n",
    "\n",
    "x_train_04567_labeled, y_train_04567_labeled, input_shape = preprocess_data(x_train_04567_labeled, y_train_04567_labeled)\n",
    "x_test_04567, y_test_04567, _ = preprocess_data(x_test_04567, y_test_04567)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T09:53:50.259605",
     "start_time": "2017-10-25T09:53:50.253590"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# image augumentation\n",
    "rotation_range = 30\n",
    "width_shift_range = 0.2\n",
    "height_shift_range = 0.2\n",
    "shear_range = 0.2\n",
    "fill_mode = 'nearest'\n",
    "x_train_04567_aug = ImageDataGenerator(\n",
    "    rotation_range = rotation_range,\n",
    "    shear_range = shear_range,\n",
    "    width_shift_range= width_shift_range,\n",
    "    height_shift_range= height_shift_range,\n",
    "    fill_mode = fill_mode\n",
    ")\n",
    "x_train_04567_aug.fit(x_train_04567_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T09:54:48.172282",
     "start_time": "2017-10-25T09:54:47.364824"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# display and generate augmented data \n",
    "def get_augmented_data(generator, x, y, N, visualize = False):\n",
    "    \"\"\"Generate augmented data.\n",
    "    \n",
    "    Params: \n",
    "    - generator: ImageGenerator \n",
    "    - x: X data\n",
    "    - y: y data\n",
    "    - N: number of images to generates per class\n",
    "    - visualize: whether to visualize the augmented images\n",
    "    \n",
    "    Return: (x, y) augmneted data\n",
    "    \"\"\"\n",
    "    \n",
    "    x_train_04567_aug_generated = []\n",
    "    y_train_04567_aug_generated = []\n",
    "\n",
    "    data_len = len(x)    \n",
    "    data_gen = generator.flow(x, y, batch_size = data_len)\n",
    "    num_batch_print = 2\n",
    "    num_columns = 2\n",
    "\n",
    "    for i, data_batch in enumerate(data_gen):    \n",
    "        if N <= i: # in every iteration, one instance per class is generated\n",
    "            break\n",
    "       \n",
    "        x_batch, y_batch = data_batch\n",
    "        #save data\n",
    "        x_train_04567_aug_generated.append(x_batch)\n",
    "        y_train_04567_aug_generated.append(y_batch)\n",
    "        \n",
    "        if visualize: # visualize the augmented results\n",
    "            f, axarr = plt.subplots(data_len, num_columns, figsize = (5, 5))\n",
    "            for j in range(len(x_batch)):\n",
    "                ground_ind = np.where(y == y_batch[j])\n",
    "                axarr[j, 0].imshow(x[ground_ind].reshape((28,28)), cmap='gray')   \n",
    "                axarr[j, 1].imshow(x_batch[j].reshape((28,28)), cmap='gray')\n",
    "                axarr[j, 0].axis('off')\n",
    "                axarr[j, 1].axis('off')\n",
    "            print(i)\n",
    "            plt.show()\n",
    "    \n",
    "    x_train_04567_aug_generated[-1]\n",
    "    # reshaping such that the array has the shape of (# data, 28, 28, 1)\n",
    "    x_train_04567_aug_generated = np.array(x_train_04567_aug_generated).reshape((-1, 28, 28, 1)) \n",
    "  \n",
    "    #reshaping to shape of (# data)\n",
    "    y_train_04567_aug_generated = np.array(y_train_04567_aug_generated).reshape((-1)) \n",
    "#    modulo = N % data_len\n",
    "#     if modulo != 0:\n",
    "#         x_train_04567_aug_generated = x_train_04567_aug_generated[0 : -(data_len-modulo)]\n",
    "#         y_train_04567_aug_generated = y_train_04567_aug_generated[0 : -(data_len-modulo)]\n",
    "#         print(\"Readjusting the shape. The shape is %s \" % (x_train_04567_aug_generated.shape, ))\n",
    "        #print(\"Warning: The data lenght will be slightly bigger than N, because N is not divadable by size of data.\")\n",
    "    return x_train_04567_aug_generated, y_train_04567_aug_generated\n",
    "\n",
    "x_train_04567_aug_generated, y_train_04567_aug_generated = get_augmented_data(generator = x_train_04567_aug, \n",
    "                                                                              x = x_train_04567_labeled,\n",
    "                                                                              y = y_train_04567_labeled,\n",
    "                                                                              N = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T09:54:48.410054",
     "start_time": "2017-10-25T09:54:48.277705"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training pairs is 9990 \n"
     ]
    }
   ],
   "source": [
    "# create training+test positive and negative pairs\n",
    "def create_pairs(x, class_indices, num_classes):\n",
    "    '''Positive and negative pair creation.\n",
    "    Alternates between positive and negative pairs. \n",
    "\n",
    "    Maximally creates (min(class_size) - 1) * num_classes pairs.\n",
    "    '''\n",
    "    pairs = []\n",
    "    labels = []    \n",
    "    n = min([len(class_indices[d]) for d in range(num_classes)]) - 1\n",
    "    for d in range(num_classes):\n",
    "        for i in range(n):\n",
    "            z1, z2 = class_indices[d][i], class_indices[d][i+1]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            inc = random.randrange(1, num_classes)\n",
    "            dn = (d + inc) % num_classes # this guarantees that the same class will not be selected\n",
    "            z1, z2 = class_indices[d][i], class_indices[dn][i]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            labels += [1, 0]\n",
    "    return np.array(pairs), np.array(labels)\n",
    "\n",
    "ind_04567 = [0,4,5,6,7]\n",
    "class_indices = [np.where(y_train_04567_aug_generated == i)[0] for i in ind_04567]\n",
    "x_train_pairs, y_train_pairs = create_pairs(x_train_04567_aug_generated, class_indices, int(num_classes / 2))\n",
    "print(\"Number of training pairs is %d \" % x_train_pairs.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T09:55:07.403709",
     "start_time": "2017-10-25T09:55:07.125971"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\azika\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:38: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=[<tf.Tenso...)`\n"
     ]
    }
   ],
   "source": [
    "# model definition\n",
    "def create_base_network(input_shape):\n",
    "    '''Base network to be shared (eq. to feature extraction).\n",
    "    '''\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    return model\n",
    "\n",
    "def get_abs_diff(vects):\n",
    "    x, y = vects\n",
    "    return K.abs(x - y)  \n",
    "\n",
    "def abs_diff_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return shape1  \n",
    "\n",
    "base_network = create_base_network(input_shape)\n",
    "\n",
    "input_a = Input(shape = input_shape)\n",
    "input_b = Input(shape = input_shape)\n",
    "\n",
    "# because we re-use the same instance `base_network`,\n",
    "# the weights of the network will be shared across the two branches\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "abs_diff = Lambda(get_abs_diff, output_shape = abs_diff_output_shape)([processed_a, processed_b])\n",
    "\n",
    "flattened_weighted_distance = Dense(1, activation = 'sigmoid')(abs_diff)\n",
    "\n",
    "siamese_model = Model(input=[input_a, input_b], output = flattened_weighted_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T10:13:31.354582",
     "start_time": "2017-10-25T10:02:03.628150"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\azika\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:24: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "9990/9990 [==============================] - 34s - loss: 0.6283 - acc: 0.6362    \n",
      "Epoch 2/20\n",
      "9990/9990 [==============================] - 35s - loss: 0.6215 - acc: 0.6507    \n",
      "Epoch 3/20\n",
      "9990/9990 [==============================] - 33s - loss: 0.6177 - acc: 0.6550    \n",
      "Epoch 4/20\n",
      "9990/9990 [==============================] - 33s - loss: 0.6167 - acc: 0.6614    \n",
      "Epoch 5/20\n",
      "9990/9990 [==============================] - 33s - loss: 0.6102 - acc: 0.6689    \n",
      "Epoch 6/20\n",
      "9990/9990 [==============================] - 33s - loss: 0.6002 - acc: 0.6758    \n",
      "Epoch 7/20\n",
      "9990/9990 [==============================] - 33s - loss: 0.5971 - acc: 0.6807    \n",
      "Epoch 8/20\n",
      "9990/9990 [==============================] - 34s - loss: 0.5947 - acc: 0.6800    \n",
      "Epoch 9/20\n",
      "9990/9990 [==============================] - 32s - loss: 0.5929 - acc: 0.6831    \n",
      "Epoch 10/20\n",
      "9990/9990 [==============================] - 32s - loss: 0.5915 - acc: 0.6818    \n",
      "Epoch 11/20\n",
      "9990/9990 [==============================] - 36s - loss: 0.5888 - acc: 0.6946    \n",
      "Epoch 12/20\n",
      "9990/9990 [==============================] - 34s - loss: 0.5881 - acc: 0.6778    \n",
      "Epoch 13/20\n",
      "9990/9990 [==============================] - 34s - loss: 0.5889 - acc: 0.6847    \n",
      "Epoch 14/20\n",
      "9990/9990 [==============================] - 36s - loss: 0.5818 - acc: 0.6987    \n",
      "Epoch 15/20\n",
      "9990/9990 [==============================] - 36s - loss: 0.5868 - acc: 0.6872    \n",
      "Epoch 16/20\n",
      "9990/9990 [==============================] - 36s - loss: 0.5827 - acc: 0.6924    \n",
      "Epoch 17/20\n",
      "9990/9990 [==============================] - 33s - loss: 0.5861 - acc: 0.6868    \n",
      "Epoch 18/20\n",
      "9990/9990 [==============================] - 34s - loss: 0.5835 - acc: 0.6920    \n",
      "Epoch 19/20\n",
      "9990/9990 [==============================] - 33s - loss: 0.5803 - acc: 0.6937    \n",
      "Epoch 20/20\n",
      "9990/9990 [==============================] - 34s - loss: 0.5802 - acc: 0.6957    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xf65b602ac8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "def step_decay(epoch):\n",
    "    '''Learning rate step decay following the original paper.'''\n",
    "    initial_lrate = 0.001\n",
    "    drop = 0.99\n",
    "    epochs_drop = 1\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "\n",
    "nb_epoch = 20\n",
    "optimizer = Adam()\n",
    "siamese_model.compile(loss = 'binary_crossentropy', optimizer = optimizer, metrics = ['accuracy'])\n",
    "\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "callbacks_list = [lrate]\n",
    "\n",
    "siamese_model.fit([x_train_pairs[:, 0], x_train_pairs[:, 1]], #pairs \n",
    "          y_train_pairs, #labels of the pairs\n",
    "          # callbacks = callbacks_list,\n",
    "          batch_size=128,\n",
    "          nb_epoch=nb_epoch)\n",
    " siamese_model.save('siamese_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T10:25:31.668745",
     "start_time": "2017-10-25T10:25:31.659722"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# generate examples (k per class) that will be couples with test data\n",
    "k = 4 # k from from analogy of k-means\n",
    "x_test_04567_aug_generated, y_test_04567_aug_generated = get_augmented_data(generator = x_train_04567_aug, \n",
    "                                                                            x = x_train_04567_labeled,\n",
    "                                                                            y = y_train_04567_labeled,\n",
    "                                                                            N = k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-10-25T08:25:32.130Z"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# create pairs\n",
    "x_test_pairs = np.array(list(product(x_test_04567, x_test_04567_aug_generated)))\n",
    "\n",
    "# predict the probability of a pair being similar. \n",
    "y_test_pred_prob = siamese_model.predict([x_test_pairs[:, 0], x_test_pairs[:, 1]])\n",
    "\n",
    "# reshaping such that each row contains k*number of class probabilities \n",
    "y_test_pred_prob = y_test_pred_prob.reshape(len(x_test_04567), len(x_test_04567_aug_generated))\n",
    "\n",
    "# getting top k prediction for a class\n",
    "y_test_pred_class_inds = y_test_pred_prob.argsort(axis = 1)[:, -k:]\n",
    "\n",
    "# like argsort but only for the highest score\n",
    "#y_test_pred_class_inds = np.argmax(y_test_pred_prob, axis = 1)\n",
    "\n",
    "# reverse order -> the highest prob is on the first place (This does not work! it reserve the data )\n",
    "#y_test_pred_class_inds = y_test_pred_class_inds[::-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-10-25T08:25:32.633Z"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# generating class prediction\n",
    "y_test_pred_k = np.array([mode(y_test_04567_aug_generated[y_test_pred_class_inds[i]]) \n",
    "                                for i in range(len(y_test_pred_class_inds))])[:, 0]\n",
    "y_test_pred_k = y_test_pred_k.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-10-25T08:25:33.122Z"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# how many prediction per class\n",
    "np.unique(y_test_pred_k, return_counts= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-10-25T08:25:33.761Z"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# final accuracy\n",
    "test_accur = np.sum(y_test_pred_k == y_test_04567) / len(y_test_04567)\n",
    "print('* Accuracy of classifying the test set: {:.2%}'.format(test_accur))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
